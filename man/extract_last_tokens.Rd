% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prediction.R
\name{extract_last_tokens}
\alias{extract_last_tokens}
\title{Extract last k tokens from input text}
\usage{
extract_last_tokens(input, k = 2)
}
\arguments{
\item{input}{Character string. The input text to extract tokens from.
Can be a sentence, phrase, or any text string.}

\item{k}{Integer. Maximum number of tokens to extract from the end of the input
(default: 2). This typically corresponds to the order of the language model:
\itemize{
  \item k=1 for bigram models (need 1 previous word)  
  \item k=2 for trigram models (need 2 previous words)
}}
}
\value{
Character vector of length <= k containing the last tokens from the
  cleaned input text. Tokens are:
  \itemize{
    \item Lowercased and cleaned using \code{clean_text()}
    \item Split on whitespace
    \item Empty strings removed
    \item Returned in original order (first element = earliest token)
  }
  Returns \code{character(0)} if no valid tokens are found.
}
\description{
Extracts and cleans the last k tokens from input text using the package's
text cleaning function. This is essential for preparing user input for
n-gram language models that need clean, tokenized context words for prediction.
}
\examples{
# Basic usage for trigram context (k=2)
extract_last_tokens("Hello world how are you?", k = 2)
# Returns: c("are", "you")

# Single token for bigram context (k=1) 
extract_last_tokens("The weather is nice", k = 1)
# Returns: "nice"

# Handle edge cases
extract_last_tokens("Single", k = 2)
# Returns: "single" (less than k tokens available)

extract_last_tokens("", k = 2)
# Returns: character(0) (no tokens)

extract_last_tokens("   Multiple    spaces   between   words   ", k = 3)
# Returns: c("between", "words") (after cleaning)

}
