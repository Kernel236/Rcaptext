% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/perplexity.R
\name{token_logprob_sb}
\alias{token_logprob_sb}
\title{Compute Log-Probability for a Single Token using Stupid Backoff}
\usage{
token_logprob_sb(
  w1,
  w2,
  target,
  tri_pruned,
  bi_pruned,
  uni_lookup,
  alpha = 0.4,
  eps = 1e-09
)
}
\arguments{
\item{w1}{Character. First context word.}

\item{w2}{Character. Second context word.}

\item{target}{Character. The target word to compute probability for.}

\item{tri_pruned}{Data frame. Pruned trigram model with columns (w1, w2, w3, p_cond).}

\item{bi_pruned}{Data frame. Pruned bigram model with columns (w1, w2, p_cond).}

\item{uni_lookup}{Data frame. Unigram lookup table with columns (word, p).}

\item{alpha}{Numeric. Backoff penalty factor (default: 0.4).}

\item{eps}{Numeric. Smoothing value to avoid log(0) (default: 1e-9).}
}
\value{
Numeric. Natural log-probability (single value).
}
\description{
Internal helper function that computes the log-probability of a target token
given a two-word context (w1, w2) using the Stupid Backoff algorithm.
}
\keyword{internal}
