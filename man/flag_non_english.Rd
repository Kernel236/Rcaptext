% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_cleaning.R
\name{flag_non_english}
\alias{flag_non_english}
\title{Detect Non-English Words}
\usage{
flag_non_english(
  words,
  dict = "en_US",
  n_cores = NULL,
  parallel_threshold = 5000
)
}
\arguments{
\item{words}{Character vector. Words to check (should be in lowercase).}

\item{dict}{Character or hunspell dictionary object. Dictionary to use for
spell checking. Default is "en_US".}

\item{n_cores}{Integer. Number of CPU cores to use for parallel processing.
Default is NULL (uses parallel::detectCores() - 4). Set to 1 for sequential processing.}

\item{parallel_threshold}{Integer. Minimum number of words to trigger
parallel processing. Default is 5000.}
}
\value{
Logical vector of same length as \code{words}: TRUE indicates
  the word is probably non-English or misspelled.
}
\description{
This function uses hunspell dictionary to identify words that are likely
not English. It's useful for filtering multilingual corpora or detecting
foreign language content in predominantly English text.
Uses parallel processing for large word vectors.
}
\details{
The function applies several heuristics:
\itemize{
  \item Only checks alphabetic tokens with apostrophes
  \item Tokens with numbers or symbols are flagged as non-English
  \item Contractions with apostrophes are generally preserved
  \item Uses hunspell for spell checking remaining tokens
}

For large word vectors, the function automatically uses parallel processing.
}
\examples{
\dontrun{
# Check various words
test_words <- c("the", "amore", "london", "o'clock", "123abc", "cafÃ©")
flag_non_english(test_words)

# Use different dictionary
flag_non_english(c("colour", "color"), dict = "en_GB")

# Force sequential processing
flag_non_english(test_words, n_cores = 1)
}

}
