% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_cleaning.R
\name{flag_non_english}
\alias{flag_non_english}
\title{Detect Non-English Words}
\usage{
flag_non_english(words, dict = "en_US")
}
\arguments{
\item{words}{Character vector. Words to check (should be in lowercase).}

\item{dict}{Character or hunspell dictionary object. Dictionary to use for
spell checking. Default is "en_US".}
}
\value{
Logical vector of same length as \code{words}: TRUE indicates
  the word is probably non-English or misspelled.
}
\description{
This function uses hunspell dictionary to identify words that are likely
not English. It's useful for filtering multilingual corpora or detecting
foreign language content in predominantly English text.
}
\details{
The function applies several heuristics:
\itemize{
  \item Only checks alphabetic tokens with apostrophes
  \item Tokens with numbers or symbols are flagged as non-English
  \item Contractions with apostrophes are generally preserved
  \item Uses hunspell for spell checking remaining tokens
}
}
\examples{
\dontrun{
# Check various words
test_words <- c("the", "amore", "london", "o'clock", "123abc", "cafÃ©")
flag_non_english(test_words)

# Use different dictionary
flag_non_english(c("colour", "color"), dict = "en_GB")
}

}
