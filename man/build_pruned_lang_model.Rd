% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/language_modeling.R
\name{build_pruned_lang_model}
\alias{build_pruned_lang_model}
\title{Build a complete pruned n-gram language model}
\usage{
build_pruned_lang_model(
  freq_uni,
  freq_bi,
  freq_tri,
  min_count_bi = 2,
  min_count_tri = 2,
  topN_bi = 12,
  topN_tri = 8,
  save = FALSE,
  out_dir = "data/processed"
)
}
\arguments{
\item{freq_uni}{A data frame with unigram frequencies containing columns:
\itemize{
  \item \code{word}: The word (character)
  \item \code{n}: Frequency count (numeric)
  \item \code{p}: Marginal probability (numeric)
}}

\item{freq_bi}{A data frame with bigram frequencies containing columns:
\itemize{
  \item \code{w1}: First word (character)
  \item \code{w2}: Second word (character)
  \item \code{n}: Frequency count (numeric)
  \item \code{p}: Probability (numeric, optional)
}}

\item{freq_tri}{A data frame with trigram frequencies containing columns:
\itemize{
  \item \code{w1}: First word (character)
  \item \code{w2}: Second word (character)
  \item \code{w3}: Third word (character)
  \item \code{n}: Frequency count (numeric)
}}

\item{min_count_bi}{Minimum count threshold for bigrams (default: 2). 
Bigrams with count < min_count_bi are removed to reduce noise.}

\item{min_count_tri}{Minimum count threshold for trigrams (default: 2).
Trigrams with count < min_count_tri are removed to reduce noise.}

\item{topN_bi}{Maximum number of bigram continuations to keep per history word (default: 12).
Only the top N most probable continuations are retained for each w1.}

\item{topN_tri}{Maximum number of trigram continuations to keep per history pair (default: 8).
Only the top N most probable continuations are retained for each (w1, w2) pair.}

\item{save}{Logical. If TRUE, saves the model components as RDS files (default: FALSE).}

\item{out_dir}{Character. Output directory for RDS files if save = TRUE (default: "data/processed").
Directory is created if it doesn't exist.}
}
\value{
A list containing the complete language model:
  \itemize{
    \item \code{uni_lookup}: Unigram lookup table with columns 'next' and 'p' for fallback predictions
    \item \code{bi_pruned}: Pruned bigram model with columns w1, w2, n, p_cond
    \item \code{tri_pruned}: Pruned trigram model with columns w1, w2, w3, n, p_cond  
    \item \code{meta}: Metadata including timestamp, parameters, and size statistics
  }
}
\description{
Creates a comprehensive language model from unigram, bigram, and trigram frequency data.
The model includes conditional probabilities, pruning by minimum count and top-N filtering,
and optional persistence to RDS files. This is the main function for creating production-ready
language models for text prediction tasks.
}
\examples{
\dontrun{
# Load frequency data (typically from freq_unigrams, freq_bigrams, freq_trigrams)
uni_freq <- freq_unigrams(tokens_uni)
bi_freq <- freq_bigrams(tokens_bi) 
tri_freq <- freq_trigrams(tokens_tri)

# Build a compact language model
lang_model <- build_pruned_lang_model(
  freq_uni = uni_freq,
  freq_bi = bi_freq, 
  freq_tri = tri_freq,
  min_count_bi = 3,     # Remove rare bigrams
  min_count_tri = 2,    # Remove rare trigrams  
  topN_bi = 10,         # Keep top 10 bigram continuations
  topN_tri = 5,         # Keep top 5 trigram continuations
  save = TRUE,          # Save to RDS files
  out_dir = "models/"   # Custom output directory
)

# Check model statistics
print(lang_model$meta$sizes)

# Use for prediction
predictions <- predict_next("I love", lang_model$tri_pruned, 
                           lang_model$bi_pruned, lang_model$uni_lookup)
}

}
