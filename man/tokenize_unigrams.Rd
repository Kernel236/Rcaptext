% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{tokenize_unigrams}
\alias{tokenize_unigrams}
\title{Tokenize Text into Individual Words (Unigrams)}
\usage{
tokenize_unigrams(corpus, text_col = "text")
}
\arguments{
\item{corpus}{A tibble containing at least a text column, typically from
\code{\link{load_corpus}} or \code{\link{sample_corpus}}.}

\item{text_col}{Character or unquoted column name containing the text to tokenize.
Default is "text".}
}
\value{
A tibble with one row per word (token) and any other preserved 
  columns from the input (e.g., source). The text column is replaced with
  a "word" column.
}
\description{
This function converts text into individual word tokens using tidytext's
tokenization engine. It's the first step in most text analysis workflows.
}
\details{
The function:
\itemize{
  \item Uses tidytext::unnest_tokens for robust tokenization
  \item Automatically converts to lowercase
  \item Removes empty or NA tokens
  \item Preserves other columns from input tibble
}
}
\examples{
\dontrun{
# Basic tokenization
corpus <- load_corpus("en_US")
unigrams <- tokenize_unigrams(corpus)
head(unigrams)

# Tokenize a specific column
custom_data <- tibble::tibble(
  id = 1:3,
  content = c("Hello world", "Text analysis", "R programming")
)
tokens <- tokenize_unigrams(custom_data, text_col = "content")
}

}
\seealso{
\code{\link{tokenize_ngrams}} for n-gram tokenization
}
