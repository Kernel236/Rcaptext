% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_cleaning.R
\name{clean_text}
\alias{clean_text}
\title{Clean and Normalize Text Data}
\usage{
clean_text(
  x,
  keep_hashtag_word = TRUE,
  n_cores = NULL,
  parallel_threshold = 1000
)
}
\arguments{
\item{x}{Character vector. Input text to be cleaned.}

\item{keep_hashtag_word}{Logical. If TRUE, removes the '#' symbol but keeps
the hashtag word. If FALSE, removes hashtags entirely. Default is TRUE.}

\item{n_cores}{Integer. Number of CPU cores to use for parallel processing.
Default is NULL (uses parallel::detectCores() - 4). Set to 1 for sequential processing.}

\item{parallel_threshold}{Integer. Minimum number of text items to trigger
parallel processing. Default is 1000. Smaller datasets are processed sequentially.}
}
\value{
Character vector of the same length as input, with cleaned text.
}
\description{
This function performs comprehensive text cleaning and normalization,
including URL removal, social media cleanup, and character standardization.
It's specifically designed for preprocessing social media and web text data.
Uses parallel processing for large text vectors.
}
\details{
The cleaning process includes:
\itemize{
  \item Convert to lowercase
  \item Remove URLs (http/https and www links)
  \item Remove @mentions
  \item Handle hashtags (remove # but optionally keep word)
  \item Remove non-ASCII characters (emojis, special symbols)
  \item Keep only letters, apostrophes, and spaces
  \item Normalize whitespace
  \item Trim leading/trailing spaces
}

For large text vectors (>= parallel_threshold), the function automatically
uses parallel processing to speed up computation.
}
\examples{
\dontrun{
# Basic text cleaning
dirty_text <- c(
  "Check this out! https://example.com #amazing @friend",
  "Hello world! ðŸ˜Š It's a beautiful day... #sunshine",
  "Visit www.google.com for more info!"
)
clean_text(dirty_text)

# Remove hashtag words entirely
clean_text(dirty_text, keep_hashtag_word = FALSE)

# Force sequential processing
clean_text(dirty_text, n_cores = 1)
}

}
