% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/test_trigrams.R
\name{make_test_trigrams}
\alias{make_test_trigrams}
\title{Build Test Trigrams from Held-Out Corpus}
\usage{
make_test_trigrams(
  corpus,
  text_col = "text_clean",
  prop = 0.2,
  seed = 123,
  min_words = 3,
  by_source = TRUE,
  drop_na_targets = TRUE,
  use_progress = TRUE
)
}
\arguments{
\item{corpus}{Tibble. Typically the test split from \code{\link{split_corpus}},
must contain \code{source} and a cleaned text column.}

\item{text_col}{Character. Name of the cleaned text column (default: "text_clean").}

\item{prop}{Numeric in (0,1]. Proportion of corpus rows to sample for creating
test trigrams (default: 0.2). Useful for controlling test set size.}

\item{seed}{Integer. Random seed for reproducibility (default: 123).}

\item{min_words}{Integer. Minimum number of words required in a text line after
cleaning. Lines with fewer words are dropped (default: 3, minimum for trigrams).}

\item{by_source}{Logical. If TRUE, samples proportionally within each source
category (default: TRUE).}

\item{drop_na_targets}{Logical. If TRUE, removes rows where target is NA or empty
(default: TRUE).}

\item{use_progress}{Logical. If TRUE, displays progress bars using progressr
and informative messages using cli (default: TRUE).}
}
\value{
Tibble with columns:
  \describe{
    \item{input_text}{Character. The context string "w1 w2" to feed to predict_next()}
    \item{w1}{Character. First context word}
    \item{w2}{Character. Second context word}
    \item{target}{Character. The actual next word (ground truth)}
    \item{source}{Character. Source category (blogs/news/twitter)}
  }
}
\description{
Creates test trigrams (w1, w2 â†’ target) from a held-out corpus for evaluating
language model predictions. Each row represents a prediction task where the model
must predict \code{target} given the context \code{(w1, w2)}.
}
\details{
The function:
\enumerate{
  \item Optionally samples corpus rows (stratified by source if \code{by_source=TRUE})
  \item Filters out lines with fewer than \code{min_words} tokens
  \item Tokenizes into trigrams using tidytext
  \item Splits each trigram into (w1, w2, target)
  \item Creates \code{input_text = "w1 w2"} for prediction
}

Use this output with \code{\link{predict_next}} to evaluate model accuracy:
\code{predict_next(input_text, tri_pruned, bi_pruned, uni_lookup)}
}
\examples{
\dontrun{
# Split corpus
splits <- split_corpus(corpus, prop_test = 0.1)

# Create test trigrams from test set
test_trigrams <- make_test_trigrams(
  corpus = splits$test,
  text_col = "text_clean",
  prop = 0.2,
  min_words = 4
)

# Evaluate model
predictions <- test_trigrams \%>\%
  rowwise() \%>\%
  mutate(pred = list(predict_next(input_text, tri, bi, uni, top_k=3))) \%>\%
  unnest(pred)

# Check accuracy
mean(predictions$target == predictions$word)
}

}
