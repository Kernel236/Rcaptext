% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/frequency.R
\name{freq_unigrams}
\alias{freq_unigrams}
\title{Compute Frequency Table for Unigrams}
\usage{
freq_unigrams(unigrams, n_cores = NULL, parallel_threshold = 1e+05)
}
\arguments{
\item{unigrams}{A tibble with a column named "word", typically from
\code{\link{tokenize_unigrams}}.}

\item{n_cores}{Integer. Number of CPU cores for parallel processing.
Default is NULL (uses parallel::detectCores() - 6). Set to 1 for sequential processing.}

\item{parallel_threshold}{Integer. Minimum number of rows to trigger parallel processing.
Default is 100000. Smaller datasets are processed sequentially.}
}
\value{
A tibble with columns:
  \describe{
    \item{word}{Character. The unique word}
    \item{n}{Integer. Count of occurrences}
    \item{p}{Numeric. Relative frequency (proportion)}
  }
  Sorted by count in descending order.
}
\description{
This function creates a frequency table from tokenized unigrams, showing
both absolute counts and relative frequencies for each unique word.
Uses parallel processing for large datasets to improve performance.
}
\details{
For large datasets (>= parallel_threshold), the function splits data into chunks,
computes partial counts in parallel, then aggregates results. This significantly
speeds up frequency computation on million-row datasets.
}
\examples{
\dontrun{
corpus <- load_corpus("en_US")
unigrams <- tokenize_unigrams(corpus)
freq_table <- freq_unigrams(unigrams)
head(freq_table)

# Check most common words
head(freq_table, 10)

# Force sequential processing
freq_seq <- freq_unigrams(unigrams, n_cores = 1)
}

}
